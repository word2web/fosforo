---
title: My summer of AI
date: 2025-10-08
lastUpdated: 2025-10-08
draft: false
tags:
  - AI 
  - careers
comments: {}
url: /my-summer-of-AI/
---
Well, that's the summer well and truly over. I work, during the daytime, with the light on again. And I'm ok with that. It's taken me a while to realise it (like 50+ years) but summer is actually my least favourite season. The pressure *to be having a good time,* to go somewhere interesting, to have something to harvest at the end of those long, hot days.

<!--more-->

 Maybe its a throwback to the school summer holidays which would begin with high hopes and ambitions for what I would do with all that *free time* and end with a sense of underachiement.

 Also in the *I don't really like summer club* is the prophet Jeremiah who wrote: "The harvest is past, the summer is ended, and we are not saved." (Jeremiah 8,20) Yip, I can relate.

This summer I found myself "between contracts" and fretting about how AI was going to render irrelevant any skills and knowledge I've managed to scrape together in almost 30 years in the workplace.

My [initial forays](obligatory-post-about-AI.md) into using large language models such as Gemini, ChatGPT and Grok had left me feeling that the game was up.
"I am *awestruck* by AI", I gushed. 

Later on I opined: "AI is a bit scary. And impressive. Scarily impressive. I'll put it bluntly: any task that can be done online is likely to be one that AI will eventually be better at than humans." 

There's nothing like re-reading my old blog posts to make me cringe.

By July I had [tempered my take on AI somewhat](staying-relevant-in-the-age-of-AI.md) and had conceeded that its progress would at some point "slow down"  but I still overestimated its abilities, most notably in coding. A summer of playing around with vibe coding, during which time I produced such masterpieces as [Find my stop](https://find-my-stop.vercel.app/) and [Radius Roulette](https://radius-roulette.vercel.app/), has persuaded me that good human programmers are going to be ok.

It would take several months more of exploring AI, talking philosophy with Grok and career development with Gemini, before I came to the conclusion - and discovered that I am not the only one to have done so - that AI, in its current offering is greatly overhyped and almost definitely a financial bubble that is waiting to pop. The longer it takes to pop, the more damage that will be done to the economy when it does.

This isn't to say that large language models aren't impressive and a remarkable discovery. But my guess is that they are something that was kind of stumbled on and instead of having some humility about that and taking time to try and fully understand it, its capabilities and limitations, the rush was on to roll it out and cash in before the flaws become too apparent. That's I think where we are now.

And the doubts are going mainsteam. Even as I began this blog post, I saw a news article that the [Bank of England itself was sounding a warning](https://www.theguardian.com/business/2025/oct/08/bank-of-england-warns-of-growing-risk-that-ai-bubble-could-burst) about the risks of an AI bubble. A bit late, perhaps.

The main problem is that AI (at least in the form of the large language models they are trying to sell us) just isn't as useful as it initially might appear and is subject to the law of diminishing returns. Maybe you've experienced this: you start out a chat with, say Gemini, and at first you're impressed by how sage and pertinent the responses are. You're drawn in - it feels as if the model really *understands* you. But then, after a while, you find that the conversation starts to feel repetitive and loop back in on itself - and as for the sagely advice it has handed out - maybe it wasn't that insightful after all and you are no further forward.

AI large language models are the quintessential *man in the pub* - nothing they don't know about, nothing they don't have an answer to, no sense of modesty or a willingness to admit they are out of their depth.

So my summer of AI is over and has cooled into autumn. I've been lucky to have had the time to satisfy my curiosity and dig deeper into the subject that I would have been able to do while working full time.

Some of it has been genuinely informative, like the excellent (and free) [Elements of AI](https://www.elementsofai.com/) course.

But as for large language models themselves, I find myself using them less and less. Even to help me do basic things in coding like tweaking the layout of this website. 

It still feels hit and miss and if I don't get good results first time, I usually find that no matter how I try and rephrase my prompt, I find I often have to abandon it, open a new chat, try another LLM, or even - shock, horror! - just try and work out the answer myself. 

I've also started to avoid those search engines that generate AI answers even if you haven't asked them to and I am returning to searching the web for answers the old fashioned way, while I still can. The uninvited insertion of "AI" into pretty much everything - word processing programmes, search engines, social media feeds - is unwelcome. As a human who is still going to the effort to create content, hopefully, for other human beings, I resent the idea that should I share any information or idea of value it will simply get sucked up and regurgitated without attribution or even as much as a click through. That's a rubbish deal for content creators.

And this also needs to be said: even without so called "generative" AI, we are already drowning in content. Videos, blogs, memes, images, sound clips, endless, endless hours of podcasts we will never have the time to listen to. Is another banal video creation tool to make "funny" clips of [Sam Altman pilfering GPUs or wearing a cat suit](https://petapixel.com/2025/10/02/people-are-making-ai-videos-of-sam-altman-stealing-content-on-sora-2/) really worth all that electricity, all those square miles of data centres? Are we going to burn the planet and empty the aquifers for this?

I think the AI industry has done a very good job at gaslighting us (including me) into thinking that the undeniable novelty of LLMs is something so useful and groundbreaking that it is inherently *worth* the resources and money that are being invested in it - and that its value to businesses and invidiuals is self-evident. Well, I think we will know in the next few years, maybe even sooner, if that is the case. Are enoght people, and important businesses willing to pay money for these tools?

Do I think we are going into another [AI winter](https://en.wikipedia.org/wiki/AI_winter)? No. LLMs are going to stay around. They are great at crunching text, debugging, summarising, suggesting revisions and brainstorming. But I am relieved to say, the idea that "agentic" AI is just around the corner is hype and at some point the financial bubble it has created will go pop. If I knew when, I wouldn't be writing a blog that nobody reads.

So that's where I am at the moment: sorry it's not a more worked through thinkpiece.

In short, I have come round to the view that AI as it's currently being sold to us isn't as big a threat to competent workers as I originally thought, and it's uses in the average business situation are actually quite limited. This doesn't mean that it's going to be business as usual in the coming years. I think it's going to be anything but usual. But the problems I anticipate will not be so much clever machines taking our jobs but the vulnerabilities of an economy and society that become overly reliant on a digital infrastructure that is becoming increasingly difficult and expensive to maintain.
